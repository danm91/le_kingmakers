{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96f14fc",
   "metadata": {},
   "source": [
    "## Notebook for DL Model; using i) word2vec with RNN, ii) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b6f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1168b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preproc_text import process_tweets\n",
    "from preproc_abbv import abbreviations\n",
    "from preproc_class import TextPreprocess\n",
    "\n",
    "# from danm91.le_kingmakers.le_kingmakers.preproc_text import process_tweets\n",
    "# from le_kingmakers.preproc_abbv import abbreviations\n",
    "# from le_kingmakers.preproc_class import TextPreprocess\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfab93",
   "metadata": {},
   "source": [
    "## i) Word2Vec with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff759d77",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "289c6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data from hard disk\n",
    "csv_path = os.path.join('/home/sbyhung/code/danm91/le_kingmakers/raw_data','training.1600000.processed.noemoticon.csv')\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "274b9b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample for testing\n",
    "sample_size = int(df.shape[0] * 0.005)\n",
    "data_sample = df.sample(sample_size, random_state=0)\n",
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a36439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitting data into X & y\n",
    "X = data_sample.iloc[:, 5]\n",
    "y = data_sample.iloc[:, 0]\n",
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41396305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing positive values from 4 to 1\n",
    "y = y.map({0: 0, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc6118a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning with bespoke classes\n",
    "X = X.apply(process_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29d58995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4800,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitting data train:test:val = 60:20:20\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=0, stratify=y_temp)\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(X_val.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)\n",
    "display(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115f754",
   "metadata": {},
   "source": [
    "### Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7db56",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97464272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise words\n",
    "X_train = X_train.apply(word_tokenize)\n",
    "X_test = X_test.apply(word_tokenize)\n",
    "X_val = X_val.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61c7f8",
   "metadata": {},
   "source": [
    "#### Training with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8418f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### setting parameters:\n",
    "# min_count=1 so words myst appear at least 2 times (to exclude typos)\n",
    "# vector_size=50 to control the size of the embedding space\n",
    "\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db7fe1",
   "metadata": {},
   "source": [
    "#### Converting data to feed into RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2853440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "X_val_embed = embedding(word2vec, X_val)\n",
    "\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_val_pad = pad_sequences(X_val_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f25175f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ME\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828073e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6184ec3",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b5ebf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(35, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff959249",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53d6b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c75981e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 17s 95ms/step - loss: 0.6922 - accuracy: 0.5179 - val_loss: 0.6891 - val_accuracy: 0.5487\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.6891 - accuracy: 0.5475 - val_loss: 0.6874 - val_accuracy: 0.5556\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 21s 139ms/step - loss: 0.6882 - accuracy: 0.5450 - val_loss: 0.6866 - val_accuracy: 0.5456\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 19s 123ms/step - loss: 0.6880 - accuracy: 0.5458 - val_loss: 0.6861 - val_accuracy: 0.5619\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 15s 103ms/step - loss: 0.6874 - accuracy: 0.5458 - val_loss: 0.6883 - val_accuracy: 0.5425\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.6875 - accuracy: 0.5454 - val_loss: 0.6851 - val_accuracy: 0.5506\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.6866 - accuracy: 0.5487 - val_loss: 0.6859 - val_accuracy: 0.5581\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.6853 - accuracy: 0.5571 - val_loss: 0.6856 - val_accuracy: 0.5569\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 0.6839 - accuracy: 0.5544 - val_loss: 0.6846 - val_accuracy: 0.5519\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 0.6832 - accuracy: 0.5571 - val_loss: 0.6840 - val_accuracy: 0.5531\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.6827 - accuracy: 0.5531 - val_loss: 0.6842 - val_accuracy: 0.5481\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.6814 - accuracy: 0.5550 - val_loss: 0.6847 - val_accuracy: 0.5487\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.6801 - accuracy: 0.5615 - val_loss: 0.6851 - val_accuracy: 0.5544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb06b8b9ca0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=20,\n",
    "          validation_data=(X_val_pad, y_val),\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7342ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6711111664772034, 0.5874999761581421]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334a697",
   "metadata": {},
   "source": [
    "## ii) Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cf276",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e76eaae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 200, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600, 200, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1600, 200, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same data fitted on Word2Vec\n",
    "display(X_train_pad.shape)\n",
    "display(X_test_pad.shape)\n",
    "display(X_val_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564f0c7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6b9ff",
   "metadata": {},
   "source": [
    "#### Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8814bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv1D(64, kernel_size = 3))\n",
    "    model.add(layers.Conv1D(32, kernel_size = 3))\n",
    "    model.add(layers.Conv1D(16, kernel_size = 3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(16,activation='relu'))\n",
    "    model.add(layers.Dense(8,activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_cnn_2 = init_cnn_model_2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a13b65",
   "metadata": {},
   "source": [
    "#### Fitting and printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c435fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 18ms/step - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6944 - val_accuracy: 0.5042\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.6892 - accuracy: 0.5354 - val_loss: 0.6938 - val_accuracy: 0.5333\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 0.6890 - accuracy: 0.5330 - val_loss: 0.6935 - val_accuracy: 0.5063\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.6890 - accuracy: 0.5277 - val_loss: 0.6937 - val_accuracy: 0.5118\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.6892 - accuracy: 0.5366 - val_loss: 0.6894 - val_accuracy: 0.5368\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.6896 - accuracy: 0.5289 - val_loss: 0.6937 - val_accuracy: 0.5257\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.6888 - accuracy: 0.5336 - val_loss: 0.6946 - val_accuracy: 0.5306\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.6866 - accuracy: 0.5426 - val_loss: 0.6916 - val_accuracy: 0.5167\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.6886 - accuracy: 0.5298 - val_loss: 0.6902 - val_accuracy: 0.5201\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.6885 - accuracy: 0.5360 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.6871 - accuracy: 0.5449 - val_loss: 0.6944 - val_accuracy: 0.5208\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.6854 - accuracy: 0.5476 - val_loss: 0.6920 - val_accuracy: 0.5271\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.6870 - accuracy: 0.5473 - val_loss: 0.6897 - val_accuracy: 0.5257\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.6850 - accuracy: 0.5551 - val_loss: 0.6933 - val_accuracy: 0.5340\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 0.6842 - accuracy: 0.5455 - val_loss: 0.7012 - val_accuracy: 0.5278\n",
      "The accuracy evaluated on the test set is of 57.625%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "es_2 = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model_cnn_2.fit(X_train_pad, y_train, \n",
    "          epochs=50, \n",
    "          batch_size=32,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es_2]\n",
    "         )\n",
    "\n",
    "\n",
    "res = model_cnn_2.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e15a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "le_kingmakers",
   "language": "python",
   "name": "le_kingmakers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
