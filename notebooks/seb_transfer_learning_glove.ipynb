{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zkAF6O8ZQlvW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkAF6O8ZQlvW",
    "outputId": "22d68f4f-c4fd-4f94-fe49-52b7f92d61de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "4/1AY0e-g5hCkB41svqmnH35AaBbKiBCfVelm-I6FWUNWRt_A75Ky1bnt9Q1UM\n",
      "Mounted at mnt\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"mnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xsDDK-U2TgIe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsDDK-U2TgIe",
    "outputId": "2e614097-6cf8-438f-a6ba-6b7d4fd7c3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mnt/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "# %cd \"mnt/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e30953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from preproc_text import process_tweets\n",
    "from preproc_abbv import abbreviations, convert_abbrev_in_text\n",
    "from preproc_class import TextPreprocess\n",
    "from convert_class import TextConvertAbbv\n",
    "\n",
    "# from danm91.le_kingmakers.le_kingmakers.preproc_text import process_tweets\n",
    "# from le_kingmakers.preproc_abbv import abbreviations\n",
    "# from le_kingmakers.preproc_class import TextPreprocess\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e68cbc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e68cbc6",
    "outputId": "fc4b05b6-2b97-4a98-ed20-51faff1def08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import string\n",
    "# import pickle\n",
    "# from nltk import tokenize\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from kingmakers.preproc_text import process_tweets\n",
    "# from kingmakers.preproc_abbv import abbreviations, convert_abbrev_in_text\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa57d0",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583cb156",
   "metadata": {
    "id": "583cb156"
   },
   "outputs": [],
   "source": [
    "# importing data from hard disk\n",
    "csv_path = os.path.join('/home/sbyhung/code/danm91/le_kingmakers/raw_data','training.1600000.processed.noemoticon.csv')\n",
    "df = pd.read_csv(csv_path, header=None, names = ['sentiment','id','date','query','user','tweet'])\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937477b1",
   "metadata": {
    "id": "937477b1"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('kingmakers/training.1600000.processed.noemoticon.csv', encoding='latin', names = ['sentiment','id','date','query','user','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c689939",
   "metadata": {
    "id": "6c689939"
   },
   "outputs": [],
   "source": [
    "df_test = df.sample(frac = 0.05, random_state=0)[['sentiment', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17ae144",
   "metadata": {
    "id": "e17ae144"
   },
   "outputs": [],
   "source": [
    "preprocess = Pipeline([\n",
    "    ('preprocess', TextPreprocess()),\n",
    "    ('abbreviation', TextConvertAbbv())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34633ba0",
   "metadata": {
    "id": "34633ba0"
   },
   "outputs": [],
   "source": [
    "df_test_2 = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab44ee76",
   "metadata": {
    "id": "ab44ee76"
   },
   "outputs": [],
   "source": [
    "df_test_2['tweet'] = preprocess.transform(df_test_2['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2da88a25",
   "metadata": {
    "id": "2da88a25",
    "outputId": "c924954d-02a9-48c6-bf91-7fb6d43d5a0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557138</th>\n",
       "      <td>0</td>\n",
       "      <td>want compete want hard competition want rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349381</th>\n",
       "      <td>0</td>\n",
       "      <td>seems stuck ground amarillo put ground stop fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182051</th>\n",
       "      <td>0</td>\n",
       "      <td>pinking shear rarararrrarararrbabyproofing cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571236</th>\n",
       "      <td>0</td>\n",
       "      <td>0ff t0 meetin hate people v0lunteer free timegrrr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339637</th>\n",
       "      <td>4</td>\n",
       "      <td>reply pls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350300</th>\n",
       "      <td>4</td>\n",
       "      <td>think get raise mommy salary not cavity right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651945</th>\n",
       "      <td>0</td>\n",
       "      <td>heading dmv soon quotlegallyquot ride amp avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390068</th>\n",
       "      <td>0</td>\n",
       "      <td>discouraged lack time management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058149</th>\n",
       "      <td>4</td>\n",
       "      <td>good call sukses dong selalu buat kamu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956608</th>\n",
       "      <td>4</td>\n",
       "      <td>must watch go lakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "557138           0  want compete want hard competition want rally ...\n",
       "349381           0  seems stuck ground amarillo put ground stop fl...\n",
       "182051           0  pinking shear rarararrrarararrbabyproofing cut...\n",
       "571236           0  0ff t0 meetin hate people v0lunteer free timegrrr\n",
       "1339637          4                                          reply pls\n",
       "...            ...                                                ...\n",
       "1350300          4  think get raise mommy salary not cavity right ...\n",
       "651945           0  heading dmv soon quotlegallyquot ride amp avoi...\n",
       "390068           0                   discouraged lack time management\n",
       "1058149          4             good call sukses dong selalu buat kamu\n",
       "956608           4                               must watch go lakers\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ded3889",
   "metadata": {
    "id": "0ded3889",
    "outputId": "28a8197e-7e5f-4c02-cd56-74ac53eb22a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557138</th>\n",
       "      <td>0</td>\n",
       "      <td>want compete want hard competition want rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349381</th>\n",
       "      <td>0</td>\n",
       "      <td>seems stuck ground amarillo put ground stop fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182051</th>\n",
       "      <td>0</td>\n",
       "      <td>pinking shear rarararrrarararrbabyproofing cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571236</th>\n",
       "      <td>0</td>\n",
       "      <td>0ff t0 meetin hate people v0lunteer free timegrrr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339637</th>\n",
       "      <td>4</td>\n",
       "      <td>reply pls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350300</th>\n",
       "      <td>4</td>\n",
       "      <td>think get raise mommy salary not cavity right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651945</th>\n",
       "      <td>0</td>\n",
       "      <td>heading dmv soon quotlegallyquot ride amp avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390068</th>\n",
       "      <td>0</td>\n",
       "      <td>discouraged lack time management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058149</th>\n",
       "      <td>4</td>\n",
       "      <td>good call sukses dong selalu buat kamu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956608</th>\n",
       "      <td>4</td>\n",
       "      <td>must watch go lakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "557138           0  want compete want hard competition want rally ...\n",
       "349381           0  seems stuck ground amarillo put ground stop fl...\n",
       "182051           0  pinking shear rarararrrarararrbabyproofing cut...\n",
       "571236           0  0ff t0 meetin hate people v0lunteer free timegrrr\n",
       "1339637          4                                          reply pls\n",
       "...            ...                                                ...\n",
       "1350300          4  think get raise mommy salary not cavity right ...\n",
       "651945           0  heading dmv soon quotlegallyquot ride amp avoi...\n",
       "390068           0                   discouraged lack time management\n",
       "1058149          4             good call sukses dong selalu buat kamu\n",
       "956608           4                               must watch go lakers\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f1adc93",
   "metadata": {
    "id": "5f1adc93"
   },
   "outputs": [],
   "source": [
    "df_test_prep = df_test\n",
    "df_test_prep['tweet'] = df_test_prep['tweet'].apply(lambda x: process_tweets(x))\n",
    "df_test_prep['tweet'] = df_test_prep['tweet'].apply(lambda x: convert_abbrev_in_text(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2b993",
   "metadata": {
    "id": "32f2b993"
   },
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6800e6a7",
   "metadata": {
    "id": "6800e6a7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "519ecf88",
   "metadata": {
    "id": "519ecf88"
   },
   "outputs": [],
   "source": [
    "X=df_test_prep['tweet']\n",
    "y=df_test_prep['sentiment']\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.20,random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786d8171",
   "metadata": {
    "id": "786d8171"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_token = [word_tokenize(i) for i in X_train]\n",
    "\n",
    "\n",
    "X_test_token = [word_tokenize(i) for i in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "BM7URG5ON8LF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM7URG5ON8LF",
    "outputId": "30fda181-b454-4f9d-ebc8-52ba0c2aaf51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139181     good newsand fridayeven better yeah laugh shal...\n",
       "844880                                     thank going watch\n",
       "1042124    ah see got hopeful determined part going rest ...\n",
       "796702                                            miss skank\n",
       "667179                                 drop toilet like wife\n",
       "                                 ...                        \n",
       "386679     stuck car park docklands manage finish dinner ...\n",
       "811423                  hi nice emeet pretty good hows thing\n",
       "467604     really need sleep seeing not spell right ahhh ...\n",
       "223189                                             next year\n",
       "871289                 awww great way start day old daughter\n",
       "Name: tweet, Length: 51200, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "V-yOQ_W4i8JI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "V-yOQ_W4i8JI",
    "outputId": "0b55751e-8f58-4b8d-a63b-6e1cf7588b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word2vec_transfer = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Immf_mxfNJ4t",
   "metadata": {
    "id": "Immf_mxfNJ4t"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mVSAWsKaNN_-",
   "metadata": {
    "id": "mVSAWsKaNN_-"
   },
   "outputs": [],
   "source": [
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train_token)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ghcdyjiCV-_g",
   "metadata": {
    "id": "ghcdyjiCV-_g"
   },
   "outputs": [],
   "source": [
    "maxlen = len(X_train_embed_2[0])\n",
    "for i in X_train_embed_2:\n",
    "  if len(i) > maxlen:\n",
    "    maxlen = len(i) \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "WPh4uvmAWafq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPh4uvmAWafq",
    "outputId": "caf5a8b4-38f9-41de-bb48-2c06589d2148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc770bb",
   "metadata": {
    "id": "5cc770bb"
   },
   "outputs": [],
   "source": [
    "X_train_pad_2 = pad_sequences(X_train_embed_2, dtype='float32', padding='post')\n",
    "X_test_pad_2 = pad_sequences(X_test_embed_2, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H6ZQsi9BkuVO",
   "metadata": {
    "id": "H6ZQsi9BkuVO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "g7_kRavBjtsf",
   "metadata": {
    "id": "g7_kRavBjtsf"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.map(lambda x: 1 if x==4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "grc301a6by87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grc301a6by87",
    "outputId": "7d2ddb38-0e00-499e-e2e8-4309ba8bf612"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139181     0\n",
       "844880     1\n",
       "1042124    1\n",
       "796702     0\n",
       "667179     0\n",
       "          ..\n",
       "386679     0\n",
       "811423     1\n",
       "467604     0\n",
       "223189     0\n",
       "871289     1\n",
       "Name: sentiment, Length: 51200, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "D4lZXeIqobSb",
   "metadata": {
    "id": "D4lZXeIqobSb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "oZjtKJf7nOO3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZjtKJf7nOO3",
    "outputId": "be4c383a-458c-4b68-efd9-ec0181d08344"
   },
   "outputs": [],
   "source": [
    "def glove_lstm():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.Masking())\n",
    "    \n",
    "    model.add(Bidirectional(layers.LSTM(\n",
    "        28, \n",
    "        return_sequences = True, \n",
    "        recurrent_dropout=0.2\n",
    "    )))\n",
    "    \n",
    "    model.add(layers.GlobalMaxPool1D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(28, activation = \"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(28, activation = \"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1 = glove_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59c21c13",
   "metadata": {
    "id": "59c21c13"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=50, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "L58TTQ6fsgLL",
   "metadata": {
    "id": "L58TTQ6fsgLL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(64, activation='tanh'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "      \n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "JaSvQO7IOy5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JaSvQO7IOy5e",
    "outputId": "76e8c64a-bf0d-487b-f03a-1df75fa6adc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "560/560 [==============================] - 16s 25ms/step - loss: 0.5240 - accuracy: 0.7407 - val_loss: 0.4984 - val_accuracy: 0.7523\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 13s 22ms/step - loss: 0.4803 - accuracy: 0.7677 - val_loss: 0.4918 - val_accuracy: 0.7581\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.4613 - accuracy: 0.7796 - val_loss: 0.4774 - val_accuracy: 0.7687\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 16s 29ms/step - loss: 0.4446 - accuracy: 0.7901 - val_loss: 0.4775 - val_accuracy: 0.7712\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 16s 28ms/step - loss: 0.4297 - accuracy: 0.7984 - val_loss: 0.4769 - val_accuracy: 0.7749\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 15s 26ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.4880 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.3969 - accuracy: 0.8173 - val_loss: 0.4850 - val_accuracy: 0.7712\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.3789 - accuracy: 0.8275 - val_loss: 0.4995 - val_accuracy: 0.7633\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.3593 - accuracy: 0.8391 - val_loss: 0.5069 - val_accuracy: 0.7676\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.3410 - accuracy: 0.8499 - val_loss: 0.5439 - val_accuracy: 0.7583\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.3207 - accuracy: 0.8608 - val_loss: 0.5662 - val_accuracy: 0.7670\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 15s 26ms/step - loss: 0.3006 - accuracy: 0.8669 - val_loss: 0.5810 - val_accuracy: 0.7585\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.2814 - accuracy: 0.8775 - val_loss: 0.6345 - val_accuracy: 0.7554\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 13s 23ms/step - loss: 0.2628 - accuracy: 0.8882 - val_loss: 0.6315 - val_accuracy: 0.7497\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.2420 - accuracy: 0.8992 - val_loss: 0.7055 - val_accuracy: 0.7477\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.2234 - accuracy: 0.9066 - val_loss: 0.7870 - val_accuracy: 0.7405\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.2062 - accuracy: 0.9144 - val_loss: 0.8317 - val_accuracy: 0.7428\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 15s 26ms/step - loss: 0.1891 - accuracy: 0.9224 - val_loss: 0.8634 - val_accuracy: 0.7375\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 14s 26ms/step - loss: 0.1749 - accuracy: 0.9289 - val_loss: 0.9194 - val_accuracy: 0.7357\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.1599 - accuracy: 0.9355 - val_loss: 0.9824 - val_accuracy: 0.7441\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.1457 - accuracy: 0.9428 - val_loss: 1.1266 - val_accuracy: 0.7414\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.1330 - accuracy: 0.9467 - val_loss: 1.1603 - val_accuracy: 0.7372\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.1208 - accuracy: 0.9524 - val_loss: 1.2767 - val_accuracy: 0.7374\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 15s 26ms/step - loss: 0.1106 - accuracy: 0.9573 - val_loss: 1.3278 - val_accuracy: 0.7372\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 15s 27ms/step - loss: 0.1021 - accuracy: 0.9610 - val_loss: 1.4288 - val_accuracy: 0.7356\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0924 - accuracy: 0.9657 - val_loss: 1.5176 - val_accuracy: 0.7314\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0859 - accuracy: 0.9670 - val_loss: 1.5871 - val_accuracy: 0.7340\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0785 - accuracy: 0.9704 - val_loss: 1.7190 - val_accuracy: 0.7317\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.0721 - accuracy: 0.9729 - val_loss: 1.7619 - val_accuracy: 0.7303\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.0682 - accuracy: 0.9752 - val_loss: 1.8748 - val_accuracy: 0.7296\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 15s 27ms/step - loss: 0.0634 - accuracy: 0.9768 - val_loss: 2.0384 - val_accuracy: 0.7329\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 1.9752 - val_accuracy: 0.7260\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0556 - accuracy: 0.9792 - val_loss: 2.1777 - val_accuracy: 0.7304\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0538 - accuracy: 0.9792 - val_loss: 2.1124 - val_accuracy: 0.7266\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 2.2317 - val_accuracy: 0.7255\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0501 - accuracy: 0.9814 - val_loss: 2.2930 - val_accuracy: 0.7277\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 2.3602 - val_accuracy: 0.7318\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 15s 26ms/step - loss: 0.0446 - accuracy: 0.9830 - val_loss: 2.3854 - val_accuracy: 0.7330\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 2.4916 - val_accuracy: 0.7268\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 2.5198 - val_accuracy: 0.7299\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 12s 22ms/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 2.5307 - val_accuracy: 0.7339\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 13s 23ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 2.5551 - val_accuracy: 0.7253\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0386 - accuracy: 0.9858 - val_loss: 2.6852 - val_accuracy: 0.7296\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 14s 26ms/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 2.6835 - val_accuracy: 0.7234\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 14s 26ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 2.8571 - val_accuracy: 0.7308\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 2.8486 - val_accuracy: 0.7242\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0348 - accuracy: 0.9871 - val_loss: 2.8606 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 2.9178 - val_accuracy: 0.7287\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 14s 25ms/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 3.0431 - val_accuracy: 0.7331\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 14s 24ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 2.9569 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 15s 27ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 2.9218 - val_accuracy: 0.7227\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 13s 23ms/step - loss: 0.0324 - accuracy: 0.9874 - val_loss: 3.0866 - val_accuracy: 0.7259\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 13s 23ms/step - loss: 0.0331 - accuracy: 0.9881 - val_loss: 3.1460 - val_accuracy: 0.7255\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 3.1129 - val_accuracy: 0.7288\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 13s 24ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 3.1121 - val_accuracy: 0.7260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4d7383c40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad_2, y_train, \n",
    "          batch_size = 64,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "AlWnHJlWpEs1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlWnHJlWpEs1",
    "outputId": "9142d1fc-a0bb-4ca9-f5ff-25ba38bdb6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "560/560 [==============================] - 32s 51ms/step - loss: 0.6753 - accuracy: 0.6127 - val_loss: 0.5458 - val_accuracy: 0.7329\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.5526 - accuracy: 0.7302 - val_loss: 0.5104 - val_accuracy: 0.7492\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.5273 - accuracy: 0.7511 - val_loss: 0.4914 - val_accuracy: 0.7624\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 19s 34ms/step - loss: 0.5116 - accuracy: 0.7622 - val_loss: 0.4838 - val_accuracy: 0.7695\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 19s 34ms/step - loss: 0.5036 - accuracy: 0.7674 - val_loss: 0.4789 - val_accuracy: 0.7712\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4969 - accuracy: 0.7727 - val_loss: 0.4753 - val_accuracy: 0.7719\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4913 - accuracy: 0.7725 - val_loss: 0.4785 - val_accuracy: 0.7718\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4854 - accuracy: 0.7763 - val_loss: 0.4745 - val_accuracy: 0.7714\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4811 - accuracy: 0.7771 - val_loss: 0.4734 - val_accuracy: 0.7731\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4756 - accuracy: 0.7834 - val_loss: 0.4743 - val_accuracy: 0.7755\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4750 - accuracy: 0.7834 - val_loss: 0.4732 - val_accuracy: 0.7786\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4678 - accuracy: 0.7868 - val_loss: 0.4697 - val_accuracy: 0.7781\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4675 - accuracy: 0.7871 - val_loss: 0.4716 - val_accuracy: 0.7758\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4630 - accuracy: 0.7920 - val_loss: 0.4698 - val_accuracy: 0.7767\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4568 - accuracy: 0.7927 - val_loss: 0.4723 - val_accuracy: 0.7805\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4539 - accuracy: 0.7939 - val_loss: 0.4720 - val_accuracy: 0.7799\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4496 - accuracy: 0.7988 - val_loss: 0.4690 - val_accuracy: 0.7803\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4471 - accuracy: 0.7972 - val_loss: 0.4744 - val_accuracy: 0.7772\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4427 - accuracy: 0.8012 - val_loss: 0.4763 - val_accuracy: 0.7785\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4416 - accuracy: 0.8031 - val_loss: 0.4826 - val_accuracy: 0.7794\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4372 - accuracy: 0.8044 - val_loss: 0.4826 - val_accuracy: 0.7800\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4382 - accuracy: 0.8038 - val_loss: 0.4764 - val_accuracy: 0.7761\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4320 - accuracy: 0.8089 - val_loss: 0.4787 - val_accuracy: 0.7771\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4281 - accuracy: 0.8073 - val_loss: 0.4793 - val_accuracy: 0.7766\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4217 - accuracy: 0.8087 - val_loss: 0.5089 - val_accuracy: 0.7717\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 19s 33ms/step - loss: 0.4233 - accuracy: 0.8092 - val_loss: 0.4887 - val_accuracy: 0.7770\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4205 - accuracy: 0.8156 - val_loss: 0.4856 - val_accuracy: 0.7752\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4198 - accuracy: 0.8148 - val_loss: 0.4974 - val_accuracy: 0.7766\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4122 - accuracy: 0.8172 - val_loss: 0.4981 - val_accuracy: 0.7704\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4077 - accuracy: 0.8188 - val_loss: 0.5083 - val_accuracy: 0.7710\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4106 - accuracy: 0.8191 - val_loss: 0.5192 - val_accuracy: 0.7769\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4081 - accuracy: 0.8163 - val_loss: 0.5220 - val_accuracy: 0.7763\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.4056 - accuracy: 0.8215 - val_loss: 0.4940 - val_accuracy: 0.7775\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.4032 - accuracy: 0.8220 - val_loss: 0.5009 - val_accuracy: 0.7731\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3979 - accuracy: 0.8256 - val_loss: 0.5268 - val_accuracy: 0.7760\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3988 - accuracy: 0.8267 - val_loss: 0.5313 - val_accuracy: 0.7758\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3916 - accuracy: 0.8295 - val_loss: 0.5138 - val_accuracy: 0.7743\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3913 - accuracy: 0.8291 - val_loss: 0.5481 - val_accuracy: 0.7610\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3855 - accuracy: 0.8316 - val_loss: 0.5407 - val_accuracy: 0.7688\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3854 - accuracy: 0.8299 - val_loss: 0.5223 - val_accuracy: 0.7735\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3828 - accuracy: 0.8331 - val_loss: 0.5586 - val_accuracy: 0.7732\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3794 - accuracy: 0.8346 - val_loss: 0.5399 - val_accuracy: 0.7616\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3798 - accuracy: 0.8355 - val_loss: 0.5311 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5353 - val_accuracy: 0.7703\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3766 - accuracy: 0.8393 - val_loss: 0.5313 - val_accuracy: 0.7720\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3733 - accuracy: 0.8377 - val_loss: 0.5601 - val_accuracy: 0.7721\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3723 - accuracy: 0.8377 - val_loss: 0.5774 - val_accuracy: 0.7693\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3678 - accuracy: 0.8386 - val_loss: 0.5656 - val_accuracy: 0.7707\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.3660 - accuracy: 0.8428 - val_loss: 0.5812 - val_accuracy: 0.7684\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3667 - accuracy: 0.8421 - val_loss: 0.5453 - val_accuracy: 0.7686\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3632 - accuracy: 0.8445 - val_loss: 0.5574 - val_accuracy: 0.7706\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3617 - accuracy: 0.8421 - val_loss: 0.5979 - val_accuracy: 0.7664\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3592 - accuracy: 0.8454 - val_loss: 0.5713 - val_accuracy: 0.7607\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3553 - accuracy: 0.8469 - val_loss: 0.5786 - val_accuracy: 0.7658\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3552 - accuracy: 0.8479 - val_loss: 0.5874 - val_accuracy: 0.7685\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.3542 - accuracy: 0.8500 - val_loss: 0.5639 - val_accuracy: 0.7640\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3514 - accuracy: 0.8512 - val_loss: 0.6248 - val_accuracy: 0.7644\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3472 - accuracy: 0.8527 - val_loss: 0.6601 - val_accuracy: 0.7665\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3459 - accuracy: 0.8512 - val_loss: 0.6385 - val_accuracy: 0.7604\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.3466 - accuracy: 0.8536 - val_loss: 0.5855 - val_accuracy: 0.7650\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 18s 33ms/step - loss: 0.3421 - accuracy: 0.8543 - val_loss: 0.6315 - val_accuracy: 0.7626\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3426 - accuracy: 0.8520 - val_loss: 0.6562 - val_accuracy: 0.7653\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3374 - accuracy: 0.8552 - val_loss: 0.6844 - val_accuracy: 0.7670\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3353 - accuracy: 0.8572 - val_loss: 0.6392 - val_accuracy: 0.7607\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3318 - accuracy: 0.8600 - val_loss: 0.7242 - val_accuracy: 0.7609\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3334 - accuracy: 0.8590 - val_loss: 0.6474 - val_accuracy: 0.7630\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 18s 32ms/step - loss: 0.3320 - accuracy: 0.8589 - val_loss: 0.7303 - val_accuracy: 0.7612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4d62c9400>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_pad_2, y_train, \n",
    "          batch_size = 64,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c793d8",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ac8aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv1D(64, kernel_size = 3))\n",
    "    model.add(layers.Conv1D(32, kernel_size = 3))\n",
    "    model.add(layers.Conv1D(16, kernel_size = 3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(16,activation='relu'))\n",
    "    model.add(layers.Dense(8,activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_cnn_2 = init_cnn_model_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3130847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1120/1120 [==============================] - 7s 6ms/step - loss: 0.5522 - accuracy: 0.7169 - val_loss: 0.5248 - val_accuracy: 0.7360\n",
      "Epoch 2/50\n",
      "1120/1120 [==============================] - 6s 5ms/step - loss: 0.5158 - accuracy: 0.7439 - val_loss: 0.5242 - val_accuracy: 0.7377\n",
      "Epoch 3/50\n",
      "1120/1120 [==============================] - 6s 5ms/step - loss: 0.5083 - accuracy: 0.7485 - val_loss: 0.5243 - val_accuracy: 0.7363\n",
      "Epoch 4/50\n",
      "1120/1120 [==============================] - 7s 6ms/step - loss: 0.5000 - accuracy: 0.7529 - val_loss: 0.5186 - val_accuracy: 0.7391\n",
      "Epoch 5/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4940 - accuracy: 0.7577 - val_loss: 0.5251 - val_accuracy: 0.7350\n",
      "Epoch 6/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4868 - accuracy: 0.7625 - val_loss: 0.5316 - val_accuracy: 0.7382\n",
      "Epoch 7/50\n",
      "1120/1120 [==============================] - 7s 6ms/step - loss: 0.4780 - accuracy: 0.7666 - val_loss: 0.5319 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.5283 - val_accuracy: 0.7337\n",
      "Epoch 9/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4635 - accuracy: 0.7770 - val_loss: 0.5404 - val_accuracy: 0.7337\n",
      "Epoch 10/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4584 - accuracy: 0.7783 - val_loss: 0.5350 - val_accuracy: 0.7342\n",
      "Epoch 11/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4515 - accuracy: 0.7851 - val_loss: 0.5368 - val_accuracy: 0.7347\n",
      "Epoch 12/50\n",
      "1120/1120 [==============================] - 8s 7ms/step - loss: 0.4442 - accuracy: 0.7892 - val_loss: 0.5483 - val_accuracy: 0.7322\n",
      "Epoch 13/50\n",
      "1120/1120 [==============================] - 9s 8ms/step - loss: 0.4385 - accuracy: 0.7930 - val_loss: 0.5624 - val_accuracy: 0.7270\n",
      "Epoch 14/50\n",
      "1120/1120 [==============================] - 9s 8ms/step - loss: 0.4316 - accuracy: 0.7955 - val_loss: 0.5539 - val_accuracy: 0.7283\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 12800\n  y sizes: 16000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aec7ac02000e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_pad_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The accuracy evaluated on the test set is of {res[1]*100:.3f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/le_kingmakers/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1452\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1455\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/le_kingmakers/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/le_kingmakers/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/le_kingmakers/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/le_kingmakers/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1628\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1629\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 12800\n  y sizes: 16000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "\n",
    "es_2 = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model_cnn_2.fit(X_train_pad_2, y_train, \n",
    "          epochs=50, \n",
    "          batch_size=32,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es_2]\n",
    "         )\n",
    "\n",
    "\n",
    "res = model_cnn_2.evaluate(X_test_pad_2, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea40a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570658bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "willdamann_transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "le_kingmakers",
   "language": "python",
   "name": "le_kingmakers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
